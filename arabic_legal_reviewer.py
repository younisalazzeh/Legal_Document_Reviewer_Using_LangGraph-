import os
import json
from typing import Dict, List, Any, TypedDict
from dataclasses import dataclass
from pathlib import Path
import streamlit as st
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import BaseMessage, HumanMessage, AIMessage
import PyPDF2
import docx
from io import BytesIO

# Configuration
class Config:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    MODEL_NAME = "gpt-4"
    TEMPERATURE = 0.1

# State definition for LangGraph
class ReviewState(TypedDict):
    document_text: str
    document_type: str
    language: str  # 'arabic' or 'english'
    summary: str
    risk_flags: List[Dict[str, Any]]
    lawyer_questions: List[str]
    plain_english_clauses: List[Dict[str, str]]
    current_step: str
    error: str

@dataclass
class RiskFlag:
    severity: str  # "Ù…Ù†Ø®ÙØ¶", "Ù…ØªÙˆØ³Ø·", "Ø¹Ø§Ù„ÙŠ", "Ø­Ø±Ø¬" for Arabic
    category: str
    description: str
    clause_text: str
    recommendation: str

class DocumentProcessor:
    """Handles document upload and text extraction with Arabic support"""
    
    @staticmethod
    def detect_language(text: str) -> str:
        """Detect if text is primarily Arabic or English"""
        arabic_chars = sum(1 for char in text if '\u0600' <= char <= '\u06FF')
        total_chars = len([char for char in text if char.isalpha()])
        
        if total_chars == 0:
            return "english"  # Default
        
        arabic_ratio = arabic_chars / total_chars
        return "arabic" if arabic_ratio > 0.5 else "english"
    
    @staticmethod
    def extract_text_from_pdf(file_bytes: bytes) -> str:
        try:
            pdf_reader = PyPDF2.PdfReader(BytesIO(file_bytes))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text
        except Exception as e:
            raise Exception(f"Error reading PDF: {str(e)}")
    
    @staticmethod
    def extract_text_from_docx(file_bytes: bytes) -> str:
        try:
            doc = docx.Document(BytesIO(file_bytes))
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        except Exception as e:
            raise Exception(f"Error reading DOCX: {str(e)}")
    
    @staticmethod
    def extract_text_from_txt(file_bytes: bytes) -> str:
        try:
            # Try UTF-8 first, then other encodings for Arabic
            encodings = ['utf-8', 'utf-16', 'cp1256', 'iso-8859-6']
            for encoding in encodings:
                try:
                    return file_bytes.decode(encoding)
                except UnicodeDecodeError:
                    continue
            raise Exception("Could not decode text with any supported encoding")
        except Exception as e:
            raise Exception(f"Error reading TXT: {str(e)}")

class ArabicLegalReviewAgent:
    """Legal review agent with Arabic and English support"""
    
    def __init__(self):
        if not Config.OPENAI_API_KEY:
            raise ValueError("OpenAI API key not found. Please set OPENAI_API_KEY environment variable.")
        
        self.llm = ChatOpenAI(
            model=Config.MODEL_NAME,
            temperature=Config.TEMPERATURE,
            api_key=Config.OPENAI_API_KEY
        )
        
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """Build the LangGraph workflow"""
        workflow = StateGraph(ReviewState)
        
        # Add nodes
        workflow.add_node("summarize", self._summarize_document)
        workflow.add_node("flag_risks", self._flag_risks)
        workflow.add_node("generate_questions", self._generate_lawyer_questions)
        workflow.add_node("rewrite_clauses", self._rewrite_in_plain_language)
        
        # Define the flow
        workflow.set_entry_point("summarize")
        workflow.add_edge("summarize", "flag_risks")
        workflow.add_edge("flag_risks", "generate_questions")
        workflow.add_edge("generate_questions", "rewrite_clauses")
        workflow.add_edge("rewrite_clauses", END)
        
        return workflow.compile()
    
    def _get_prompts(self, language: str) -> Dict[str, str]:
        """Get language-specific prompts"""
        
        if language == "arabic":
            return {
                "summarize": """
Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªÙ„Ø®ÙŠØµ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

Ù†Øµ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©:
{document_text}

ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:
1. Ù†ÙˆØ¹ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© ÙˆØ§Ù„ØºØ±Ø¶ Ù…Ù†Ù‡Ø§
2. Ø§Ù„Ø£Ø·Ø±Ø§Ù Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
3. Ø§Ù„Ø´Ø±ÙˆØ· ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
4. Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® ÙˆØ§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø©
5. Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©
6. Ø§Ù„Ø­Ù‚ÙˆÙ‚ ÙˆØ§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù…Ù„Ø®Øµ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙˆÙ…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙ…Ø±ÙƒØ²Ø§Ù‹ Ø¹Ù„Ù‰ Ø£Ù‡Ù… Ø§Ù„Ø¬ÙˆØ§Ù†Ø¨ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©.
""",
                
                "risks": """
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©. Ø­Ù„Ù„ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© ÙˆØ§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø­Ù…Ø±Ø§Ø¡.

Ù†Øµ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©:
{document_text}

Ù„ÙƒÙ„ Ù…Ø®Ø§Ø·Ø±Ø© ØªØ­Ø¯Ø¯Ù‡Ø§ØŒ Ù‚Ø¯Ù…:
1. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø© (Ø­Ø±Ø¬ØŒ Ø¹Ø§Ù„ÙŠØŒ Ù…ØªÙˆØ³Ø·ØŒ Ù…Ù†Ø®ÙØ¶)
2. ÙØ¦Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© (Ù…Ø§Ù„ÙŠØ©ØŒ Ù…Ø³Ø¤ÙˆÙ„ÙŠØ©ØŒ Ø§Ù…ØªØ«Ø§Ù„ØŒ Ø¥Ù†Ù‡Ø§Ø¡ØŒ Ø¥Ù„Ø®)
3. ÙˆØµÙ Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©
4. Ø§Ù„Ù†Øµ Ø£Ùˆ Ø§Ù„Ø¨Ù†Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯ Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©
5. Ø§Ù„ØªÙˆØµÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø©

Ù‚Ù… Ø¨ØªÙ†Ø³ÙŠÙ‚ Ø¥Ø¬Ø§Ø¨ØªÙƒ ÙƒÙ…ØµÙÙˆÙØ© JSON:
[
    {{
        "severity": "Ø¹Ø§Ù„ÙŠ",
        "category": "Ù…Ø§Ù„ÙŠØ©",
        "description": "ØªØ¹Ø±Ø¶ ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯ Ù„Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ©",
        "clause_text": "Ù†Øµ Ø§Ù„Ø¨Ù†Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯ Ù‡Ù†Ø§",
        "recommendation": "ÙŠÙÙ†ØµØ­ Ø¨Ø¥Ø¶Ø§ÙØ© Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ©"
    }}
]

Ø£Ø±Ø¬Ø¹ ÙÙ‚Ø· Ù…ØµÙÙˆÙØ© JSONØŒ Ø¨Ø¯ÙˆÙ† Ù†Øµ Ø¢Ø®Ø±.
""",
                
                "questions": """
Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©ØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© Ù…Ù‡Ù…Ø© ÙŠØ¬Ø¨ Ø·Ø±Ø­Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠ.

Ù…Ù„Ø®Øµ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©:
{summary}

Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©:
{risks}

Ø£Ù†Ø´Ø¦ 8-12 Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù…Ø­Ø¯Ø¯Ø§Ù‹ ÙˆÙ‚Ø§Ø¨Ù„Ø§Ù‹ Ù„Ù„ØªÙ†ÙÙŠØ° ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø·Ø±Ø­Ù‡Ø§ Ø¹Ù„Ù‰ Ù…Ø­Ø§Ù…ÙŠÙ‡ Ø­ÙˆÙ„ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©.
Ø±ÙƒØ² Ø¹Ù„Ù‰:
1. ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØºØ§Ù…Ø¶Ø©
2. ÙÙ‡Ù… ØªØ¯Ø§Ø¹ÙŠØ§Øª Ø§Ù„Ø¨Ù†ÙˆØ¯ Ø§Ù„Ù…Ø­ÙÙˆÙØ© Ø¨Ø§Ù„Ù…Ø®Ø§Ø·Ø±
3. Ø§Ù„ÙØ±Øµ Ø§Ù„ØªÙØ§ÙˆØ¶ÙŠØ©
4. Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„
5. Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø®Ø±ÙˆØ¬ ÙˆØ¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¥Ù†Ù‡Ø§Ø¡

Ù‚Ù… Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙƒÙ…ØµÙÙˆÙØ© JSON Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ:
["Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„ØŸ", "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠØŸ", ...]

Ø£Ø±Ø¬Ø¹ ÙÙ‚Ø· Ù…ØµÙÙˆÙØ© JSONØŒ Ø¨Ø¯ÙˆÙ† Ù†Øµ Ø¢Ø®Ø±.
""",
                
                "rewrite": """
Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø¥Ø¹Ø§Ø¯Ø© ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¨Ù†ÙˆØ¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø¨Ù„ØºØ© Ø¨Ø³ÙŠØ·Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø© Ù„ØºÙŠØ± Ø§Ù„Ù…Ø®ØªØµÙŠÙ† ÙÙŠ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†.

Ù†Øµ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©:
{document_text}

Ø­Ø¯Ø¯ 5-8 Ù…Ù† Ø£ÙƒØ«Ø± Ø§Ù„Ø¨Ù†ÙˆØ¯ ØªØ¹Ù‚ÙŠØ¯Ø§Ù‹ Ø£Ùˆ Ø£Ù‡Ù…ÙŠØ© ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© ÙˆØ£Ø¹Ø¯ ÙƒØªØ§Ø¨ØªÙ‡Ø§ Ø¨Ù„ØºØ© Ø¨Ø³ÙŠØ·Ø©.
Ù„ÙƒÙ„ Ø¨Ù†Ø¯:
1. Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ù…Ø¹Ù‚Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠ
2. Ù‚Ø¯Ù… Ø´Ø±Ø­Ø§Ù‹ Ø¨Ù„ØºØ© Ø¨Ø³ÙŠØ·Ø©
3. Ø§Ø´Ø±Ø­ Ù…Ø§ ÙŠØ¹Ù†ÙŠÙ‡ Ù‡Ø°Ø§ Ù…Ù† Ø§Ù„Ù†Ø§Ø­ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©

Ù‚Ù… Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙƒÙ…ØµÙÙˆÙØ© JSON:
[
    {{
        "original_clause": "Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø£ØµÙ„ÙŠ Ù‡Ù†Ø§",
        "plain_language": "Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ø¨Ø³ÙŠØ· Ù‡Ù†Ø§",
        "practical_meaning": "Ù…Ø§ ÙŠØ¹Ù†ÙŠÙ‡ Ù‡Ø°Ø§ Ù…Ù† Ø§Ù„Ù†Ø§Ø­ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©"
    }}
]

Ø£Ø±Ø¬Ø¹ ÙÙ‚Ø· Ù…ØµÙÙˆÙØ© JSONØŒ Ø¨Ø¯ÙˆÙ† Ù†Øµ Ø¢Ø®Ø±.
"""
            }
        else:  # English prompts (original)
            return {
                "summarize": """
You are a legal expert tasked with summarizing a legal document. 

Document Text:
{document_text}

Please provide a comprehensive summary that includes:
1. Document type and purpose
2. Key parties involved
3. Main terms and conditions
4. Important dates and deadlines
5. Financial obligations
6. Key rights and responsibilities

Keep the summary clear, concise, and focused on the most important legal aspects.
""",
                
                "risks": """
You are a legal risk assessment expert. Analyze the following document for potential risks and red flags.

Document Text:
{document_text}

For each risk you identify, provide:
1. Severity level (critical, high, medium, low)
2. Risk category (e.g., financial, liability, compliance, termination, etc.)
3. Description of the risk
4. Specific clause or text that contains the risk
5. Recommendation for addressing the risk

Format your response as a JSON array of risk objects:
[
    {{
        "severity": "high",
        "category": "financial",
        "description": "Unlimited liability exposure",
        "clause_text": "specific clause text here",
        "recommendation": "recommend adding liability cap"
    }}
]

Only return the JSON array, no other text.
""",
                
                "questions": """
Based on the legal document and identified risks, generate important questions that should be asked to a lawyer.

Document Summary:
{summary}

Identified Risks:
{risks}

Generate 8-12 specific, actionable questions that a client should ask their lawyer about this document. 
Focus on:
1. Clarifying ambiguous terms
2. Understanding implications of risky clauses
3. Negotiation opportunities
4. Compliance requirements
5. Exit strategies and termination procedures

Format as a JSON array of strings:
["Question 1?", "Question 2?", ...]

Only return the JSON array, no other text.
""",
                
                "rewrite": """
You are tasked with rewriting complex legal clauses in plain language to make them understandable to non-lawyers.

Document Text:
{document_text}

Identify the 5-8 most complex or important clauses in this document and rewrite them in plain language.
For each clause:
1. Extract the original complex text
2. Provide a plain language explanation
3. Highlight what this means in practical terms

Format as a JSON array:
[
    {{
        "original_clause": "original legal text here",
        "plain_language": "simple explanation here",
        "practical_meaning": "what this means in real terms"
    }}
]

Only return the JSON array, no other text.
"""
            }
    
    def _summarize_document(self, state: ReviewState) -> ReviewState:
        """Step 1: Summarize the document terms"""
        prompts = self._get_prompts(state["language"])
        prompt_template = ChatPromptTemplate.from_template(prompts["summarize"])
        
        try:
            response = self.llm.invoke(prompt_template.format(document_text=state["document_text"]))
            state["summary"] = response.content
            state["current_step"] = "summarize_complete"
        except Exception as e:
            state["error"] = f"Error in summarization: {str(e)}"
        
        return state
    
    def _flag_risks(self, state: ReviewState) -> ReviewState:
        """Step 2: Flag potential risks"""
        prompts = self._get_prompts(state["language"])
        prompt_template = ChatPromptTemplate.from_template(prompts["risks"])
        
        try:
            response = self.llm.invoke(prompt_template.format(document_text=state["document_text"]))
            risk_flags = json.loads(response.content)
            state["risk_flags"] = risk_flags
            state["current_step"] = "risk_analysis_complete"
        except Exception as e:
            state["error"] = f"Error in risk analysis: {str(e)}"
            state["risk_flags"] = []
        
        return state
    
    def _generate_lawyer_questions(self, state: ReviewState) -> ReviewState:
        """Step 3: Generate questions for a lawyer"""
        prompts = self._get_prompts(state["language"])
        prompt_template = ChatPromptTemplate.from_template(prompts["questions"])
        
        try:
            risks_text = json.dumps(state["risk_flags"], indent=2, ensure_ascii=False)
            response = self.llm.invoke(prompt_template.format(
                summary=state["summary"],
                risks=risks_text
            ))
            questions = json.loads(response.content)
            state["lawyer_questions"] = questions
            state["current_step"] = "questions_generated"
        except Exception as e:
            state["error"] = f"Error generating questions: {str(e)}"
            state["lawyer_questions"] = []
        
        return state
    
    def _rewrite_in_plain_language(self, state: ReviewState) -> ReviewState:
        """Step 4: Rewrite complex clauses in plain language"""
        prompts = self._get_prompts(state["language"])
        prompt_template = ChatPromptTemplate.from_template(prompts["rewrite"])
        
        try:
            response = self.llm.invoke(prompt_template.format(document_text=state["document_text"]))
            clauses = json.loads(response.content)
            state["plain_english_clauses"] = clauses
            state["current_step"] = "rewriting_complete"
        except Exception as e:
            state["error"] = f"Error rewriting clauses: {str(e)}"
            state["plain_english_clauses"] = []
        
        return state
    
    def review_document(self, document_text: str, document_type: str = "contract") -> ReviewState:
        """Main method to review a document"""
        
        # Detect language
        language = DocumentProcessor.detect_language(document_text)
        
        initial_state = ReviewState(
            document_text=document_text,
            document_type=document_type,
            language=language,
            summary="",
            risk_flags=[],
            lawyer_questions=[],
            plain_english_clauses=[],
            current_step="starting",
            error=""
        )
        
        try:
            result = self.graph.invoke(initial_state)
            return result
        except Exception as e:
            initial_state["error"] = f"Workflow error: {str(e)}"
            return initial_state

def main():
    """Streamlit UI with Arabic support"""
    
    st.set_page_config(
        page_title="Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© / Legal Document Reviewer",
        page_icon="âš–ï¸",
        layout="wide"
    )
    
    # Language selection
    language_option = st.selectbox(
        "Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ© / Select Language",
        ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© / Arabic", "English / Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"]
    )
    
    is_arabic_ui = language_option.startswith("Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    
    # Apply RTL CSS for Arabic
    if is_arabic_ui:
        st.markdown("""
        <style>
        .main .block-container {
            direction: rtl;
            text-align: right;
        }
        .stSelectbox label {
            direction: rtl;
        }
        .stTextArea label {
            direction: rtl;
        }
        .stFileUploader label {
            direction: rtl;
        }
        </style>
        """, unsafe_allow_html=True)
    
    # Title and description
    if is_arabic_ui:
        st.title("âš–ï¸ Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©")
        st.markdown("Ø§Ø±ÙØ¹ ÙˆØ«ÙŠÙ‚Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    else:
        st.title("âš–ï¸ Legal Document Reviewer")
        st.markdown("Upload a legal document for comprehensive AI-powered analysis")
    
    # Sidebar
    with st.sidebar:
        if is_arabic_ui:
            st.header("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
            api_key = st.text_input("Ù…ÙØªØ§Ø­ OpenAI API", type="password", value=os.getenv("OPENAI_API_KEY", ""))
            st.markdown("---")
            st.markdown("### Ø§Ù„ØµÙŠØº Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©")
            st.markdown("- PDF (.pdf)")
            st.markdown("- Word (.docx)")
            st.markdown("- Ù†Øµ (.txt)")
        else:
            st.header("Configuration")
            api_key = st.text_input("OpenAI API Key", type="password", value=os.getenv("OPENAI_API_KEY", ""))
            st.markdown("---")
            st.markdown("### Supported Formats")
            st.markdown("- PDF (.pdf)")
            st.markdown("- Word (.docx)")
            st.markdown("- Text (.txt)")
        
        if api_key:
            os.environ["OPENAI_API_KEY"] = api_key
    
    # File upload
    upload_label = "Ø§Ø®ØªØ± ÙˆØ«ÙŠÙ‚Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©" if is_arabic_ui else "Choose a legal document"
    upload_help = "Ø§Ø±ÙØ¹ Ø¹Ù‚Ø¯ Ø£Ùˆ Ø§ØªÙØ§Ù‚ÙŠØ© Ø£Ùˆ ÙˆØ«ÙŠÙ‚Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø£Ø®Ø±Ù‰ Ù„Ù„ØªØ­Ù„ÙŠÙ„" if is_arabic_ui else "Upload a contract, agreement, or other legal document for analysis"
    
    uploaded_file = st.file_uploader(
        upload_label,
        type=['pdf', 'docx', 'txt'],
        help=upload_help
    )
    
    if uploaded_file is not None:
        if not api_key:
            error_msg = "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ OpenAI API ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©." if is_arabic_ui else "Please enter your OpenAI API key in the sidebar to proceed."
            st.error(error_msg)
            return
        
        try:
            # Extract text from uploaded file
            file_bytes = uploaded_file.read()
            
            if uploaded_file.type == "application/pdf":
                document_text = DocumentProcessor.extract_text_from_pdf(file_bytes)
            elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                document_text = DocumentProcessor.extract_text_from_docx(file_bytes)
            elif uploaded_file.type == "text/plain":
                document_text = DocumentProcessor.extract_text_from_txt(file_bytes)
            else:
                error_msg = "Ù†ÙˆØ¹ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…" if is_arabic_ui else "Unsupported file type"
                st.error(error_msg)
                return
            
            if len(document_text.strip()) == 0:
                error_msg = "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ù†Øµ ÙÙŠ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©" if is_arabic_ui else "No text could be extracted from the document"
                st.error(error_msg)
                return
            
            # Detect document language
            detected_language = DocumentProcessor.detect_language(document_text)
            lang_display = "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" if detected_language == "arabic" else "Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"
            lang_display_en = "Arabic" if detected_language == "arabic" else "English"
            
            if is_arabic_ui:
                st.info(f"ğŸ” Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {lang_display}")
            else:
                st.info(f"ğŸ” Detected Language: {lang_display_en}")
            
            # Show document preview
            preview_title = "ğŸ“„ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©" if is_arabic_ui else "ğŸ“„ Document Preview"
            with st.expander(preview_title):
                preview_text = document_text[:1000] + "..." if len(document_text) > 1000 else document_text
                st.text_area("Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬" if is_arabic_ui else "Extracted Text", preview_text, height=200)
            
            # Process document
            button_text = "ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„" if is_arabic_ui else "ğŸ” Start Analysis"
            
            if st.button(button_text, type="primary"):
                progress_text = "Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¨Ø¶Ø¹ Ø¯Ù‚Ø§Ø¦Ù‚." if is_arabic_ui else "Analyzing document... This may take a few minutes."
                
                with st.spinner(progress_text):
                    try:
                        agent = ArabicLegalReviewAgent()
                        result = agent.review_document(document_text)
                        
                        if result["error"]:
                            error_msg = f"ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {result['error']}" if is_arabic_ui else f"Analysis failed: {result['error']}"
                            st.error(error_msg)
                            return
                        
                        # Display results
                        success_msg = "âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„!" if is_arabic_ui else "âœ… Analysis Complete!"
                        st.success(success_msg)
                        
                        # Summary Section
                        summary_title = "ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©" if is_arabic_ui else "ğŸ“‹ Document Summary"
                        st.header(summary_title)
                        st.markdown(result["summary"])
                        
                        # Risk Flags Section
                        risk_title = "âš ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±" if is_arabic_ui else "âš ï¸ Risk Analysis"
                        st.header(risk_title)
                        
                        if result["risk_flags"]:
                            # Arabic severity mapping
                            severity_mapping = {
                                "Ø­Ø±Ø¬": "ğŸ”´", "critical": "ğŸ”´",
                                "Ø¹Ø§Ù„ÙŠ": "ğŸŸ ", "high": "ğŸŸ ",
                                "Ù…ØªÙˆØ³Ø·": "ğŸŸ¡", "medium": "ğŸŸ¡",  
                                "Ù…Ù†Ø®ÙØ¶": "ğŸŸ¢", "low": "ğŸŸ¢"
                            }
                            
                            for i, risk in enumerate(result["risk_flags"]):
                                severity_icon = severity_mapping.get(risk["severity"], "âšª")
                                
                                if is_arabic_ui:
                                    title = f"{severity_icon} Ù…Ø®Ø§Ø·Ø±Ø© {risk['category']} - Ù…Ø³ØªÙˆÙ‰ {risk['severity']}"
                                    desc_label = "**Ø§Ù„ÙˆØµÙ:**"
                                    clause_label = "**Ø§Ù„Ø¨Ù†Ø¯ Ø°Ùˆ Ø§Ù„ØµÙ„Ø©:**"
                                    rec_label = "**Ø§Ù„ØªÙˆØµÙŠØ©:**"
                                else:
                                    title = f"{severity_icon} {risk['category'].title()} Risk - {risk['severity'].title()} Severity"
                                    desc_label = "**Description:**"
                                    clause_label = "**Relevant Clause:**"
                                    rec_label = "**Recommendation:**"
                                
                                with st.expander(title):
                                    st.markdown(f"{desc_label} {risk['description']}")
                                    st.markdown(f"{clause_label} {risk['clause_text']}")
                                    st.markdown(f"{rec_label} {risk['recommendation']}")
                        else:
                            no_risks_msg = "Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ù…Ø®Ø§Ø·Ø± ÙƒØ¨ÙŠØ±Ø©" if is_arabic_ui else "No significant risks identified"
                            st.info(no_risks_msg)
                        
                        # Lawyer Questions Section
                        questions_title = "â“ Ø£Ø³Ø¦Ù„Ø© Ù„Ù…Ø­Ø§Ù…ÙŠÙƒ" if is_arabic_ui else "â“ Questions for Your Lawyer"
                        st.header(questions_title)
                        
                        if result["lawyer_questions"]:
                            for i, question in enumerate(result["lawyer_questions"], 1):
                                st.markdown(f"{i}. {question}")
                        else:
                            no_questions_msg = "Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø£Ø³Ø¦Ù„Ø© Ù…Ø­Ø¯Ø¯Ø©" if is_arabic_ui else "No specific questions generated"
                            st.info(no_questions_msg)
                        
                        # Plain Language Section
                        plain_title = "ğŸ“ Ø§Ù„Ø¨Ù†ÙˆØ¯ Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø¨Ù„ØºØ© Ø¨Ø³ÙŠØ·Ø©" if is_arabic_ui else "ğŸ“ Complex Clauses in Plain Language"
                        st.header(plain_title)
                        
                        if result["plain_english_clauses"]:
                            for i, clause in enumerate(result["plain_english_clauses"]):
                                clause_title = f"Ø§Ù„Ø¨Ù†Ø¯ {i+1}" if is_arabic_ui else f"Clause {i+1}"
                                
                                with st.expander(clause_title):
                                    if is_arabic_ui:
                                        st.markdown("**Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø£ØµÙ„ÙŠ:**")
                                        st.code(clause["original_clause"])
                                        st.markdown("**Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©:**")
                                        st.markdown(clause["plain_language"])
                                        st.markdown("**Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø¹Ù…Ù„ÙŠ:**")
                                        st.info(clause["practical_meaning"])
                                    else:
                                        st.markdown("**Original Legal Text:**")
                                        st.code(clause["original_clause"])
                                        st.markdown("**Plain Language:**")
                                        st.markdown(clause["plain_language"])
                                        st.markdown("**Practical Meaning:**")
                                        st.info(clause["practical_meaning"])
                        else:
                            no_clauses_msg = "Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯ Ø¨Ù†ÙˆØ¯ Ù…Ø¹Ù‚Ø¯Ø© Ù„Ù„ØªØ¨Ø³ÙŠØ·" if is_arabic_ui else "No complex clauses identified for simplification"
                            st.info(no_clauses_msg)
                        
                        # Export functionality
                        export_title = "ğŸ’¾ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬" if is_arabic_ui else "ğŸ’¾ Export Results"
                        st.header(export_title)
                        
                        export_data = {
                            "document_language": result["language"],
                            "document_summary": result["summary"],
                            "risk_flags": result["risk_flags"],
                            "lawyer_questions": result["lawyer_questions"],
                            "plain_language_clauses": result["plain_english_clauses"]
                        }
                        
                        download_label = "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ (JSON)" if is_arabic_ui else "ğŸ“¥ Download Analysis Report (JSON)"
                        
                        st.download_button(
                            label=download_label,
                            data=json.dumps(export_data, indent=2, ensure_ascii=False),
                            file_name=f"legal_analysis_{uploaded_file.name}.json",
                            mime="application/json"
                        )
                        
                    except Exception as e:
                        error_msg = f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}" if is_arabic_ui else f"An error occurred during analysis: {str(e)}"
                        st.error(error_msg)
                        
        except Exception as e:
            error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {str(e)}" if is_arabic_ui else f"Error processing file: {str(e)}"
            st.error(error_msg)

if __name__ == "__main__":
    main()